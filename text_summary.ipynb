{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "atmospheric-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "progressive-hello",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
       "1  FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
       "2                  Why the Truth Might Get You Fired   \n",
       "3  15 Civilians Killed In Single US Airstrike Hav...   \n",
       "4  Iranian woman jailed for fictional unpublished...   \n",
       "\n",
       "                                                text  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...  \n",
       "1  Ever get the feeling your life circles the rou...  \n",
       "2  Why the Truth Might Get You Fired October 29, ...  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = os.path.join('datasets', 'summary_train.csv')\n",
    "train_df = pd.read_csv(train_path, usecols=['title', 'text'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "intermediate-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)\n",
    "text = train_df['text'].values\n",
    "targets = train_df['title'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "involved-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TARGETS_LENGTH = 20\n",
    "\n",
    "def preprocess_targets(targets):\n",
    "    seq_list = []\n",
    "    for line in targets:\n",
    "        words_list = []\n",
    "        sentence = '[bos] ' + line.lower() + ' [eos]'\n",
    "        sentence = sentence.split(' ')\n",
    "        for word in sentence:\n",
    "            if len(words_list) < MAX_TARGETS_LENGTH:\n",
    "                words_list.append(word)\n",
    "            else:\n",
    "                break\n",
    "        seq_list.append(words_list)\n",
    "    return seq_list\n",
    "            \n",
    "targets = preprocess_targets(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hydraulic-membership",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORDS = 10_000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=NUM_WORDS)\n",
    "tokenizer.fit_on_texts(text)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "incorporated-baseball",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {word: index for word, index in word_index.items() if index <= 10_000}\n",
    "index_word = {index: word for word, index in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "timely-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 100\n",
    "new_text = tokenizer.texts_to_sequences(text)\n",
    "new_text = pad_sequences(new_text, maxlen=MAX_LEN, \n",
    "                         truncating='post', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "developmental-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_mapping(text):\n",
    "    tokenizer = Tokenizer(num_words=NUM_WORDS)\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    word_index = tokenizer.word_index\n",
    "    word_index = {word: index for word, index in word_index.items() if index <= 10_000}\n",
    "    index_word = {index: word for word, index in word_index.items()}\n",
    "    return word_index, index_word\n",
    "\n",
    "\n",
    "\n",
    "target_word_index, target_index_word = get_words_mapping(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "protective-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_MAX_LEN = 10\n",
    "\n",
    "def get_generator(new_text, targets, batch_size=254):\n",
    "    nrows = new_text.shape[0]\n",
    "    num_batches = nrows // batch_size\n",
    "    for batch_id in range(num_batches):\n",
    "        low = batch_id * batch_size\n",
    "        upper = (batch_id + 1) * batch_size\n",
    "        encoder_input_data = new_text[low:upper]\n",
    "        decoder_output_data = np.zeros(shape=(batch_size, TARGET_MAX_LEN, NUM_WORDS + 1))\n",
    "        decoder_input_data = np.zeros(shape=(batch_size, TARGET_MAX_LEN, NUM_WORDS + 1))\n",
    "        for i, line in enumerate(targets[low:upper]):\n",
    "            for j, word in enumerate(line):\n",
    "                if j >= TARGET_MAX_LEN:\n",
    "                    break\n",
    "                try:\n",
    "                    idx = target_word_index[word]\n",
    "                except KeyError:\n",
    "                    continue\n",
    "                else:\n",
    "                    decoder_input_data[i, j, idx] = 1\n",
    "                    if i > 0:\n",
    "                        decoder_output_data[i, j-1, idx] = 1\n",
    "        yield [encoder_input_data, decoder_input_data], decoder_output_data\n",
    "        \n",
    "train_gen = get_generator(new_text, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "endless-compilation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_embedding (Embedding)   (None, None, 100)    1000100     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, None, 10001) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm (LSTM)             [(None, None, 100),  80400       encoder_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 100),  4040800     decoder_input[0][0]              \n",
      "                                                                 encoder_lstm[0][1]               \n",
      "                                                                 encoder_lstm[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 10001)  1010101     decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 6,131,401\n",
      "Trainable params: 6,131,401\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_input = Input(shape=(None,), name='encoder_input')\n",
    "encoder_embedding = Embedding(input_dim=NUM_WORDS + 1, output_dim=100, \n",
    "                              input_length=MAX_LEN, name='encoder_embedding')\n",
    "encoder_lstm = LSTM(100, return_state=True, \n",
    "                    return_sequences=True, name='encoder_lstm')\n",
    "encoder_output, encoder_state_h, encoder_state_c = encoder_lstm(encoder_embedding(encoder_input))\n",
    "encoder_states = [encoder_state_h, encoder_state_c]\n",
    "\n",
    "decoder_input = Input(shape=(None, NUM_WORDS + 1), name='decoder_input')\n",
    "decoder_lstm = LSTM(100, return_state=True, \n",
    "                    return_sequences=True, name='decoder_lstm')\n",
    "decoder_output, decoder_state_h, decoder_state_c = decoder_lstm(decoder_input, initial_state=encoder_states)\n",
    "decoder_dense = Dense(units=NUM_WORDS + 1, activation='softmax', name='decoder_dense')\n",
    "decoder_output = decoder_dense(decoder_output)\n",
    "\n",
    "model = Model([encoder_input, decoder_input], decoder_output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "normal-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_input, encoder_states)\n",
    "\n",
    "decoder_state_inputs = [Input(shape=(100,)), Input(shape=(100,))]\n",
    "decoder_output, state_h, state_c = decoder_lstm(decoder_input, initial_state=decoder_state_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_output = decoder_dense(decoder_output)\n",
    "decoder_model = Model([decoder_input] + decoder_state_inputs, [decoder_output] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "independent-eagle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5/5 [==============================] - 8s 2s/step - loss: 6.0770 - accuracy: 0.0996\n",
      "Epoch 2/3\n",
      "5/5 [==============================] - 8s 2s/step - loss: 5.9546 - accuracy: 0.0996\n",
      "Epoch 3/3\n",
      "5/5 [==============================] - 8s 2s/step - loss: 5.8195 - accuracy: 0.0996\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "history = model.fit(train_gen, steps_per_epoch=5, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-diagnosis",
   "metadata": {},
   "source": [
    "Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "optical-appreciation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ever get the feeling your life circles the roundabout rather than heads in a straight line toward the intended destination? [Hillary Clinton remains the big woman on campus in leafy, liberal Wellesley, Massachusetts. Everywhere else votes her most likely to don her inauguration dress for the remainder of her days the way Miss Havisham forever wore that wedding dress.  Speaking of Great Expectations, Hillary Rodham overflowed with them 48 years ago when she first addressed a Wellesley graduating class. The president of the college informed those gathered in 1969 that the students needed “no debate so far as I could ascertain as to who their spokesman was to be” (kind of the like the Democratic primaries in 2016 minus the   terms unknown then even at a Seven Sisters school). “I am very glad that Miss Adams made it clear that what I am speaking for today is all of us —  the 400 of us,” Miss Rodham told her classmates. After appointing herself Edger Bergen to the Charlie McCarthys and Mortimer Snerds in attendance, the    bespectacled in granny glasses (awarding her matronly wisdom —  or at least John Lennon wisdom) took issue with the previous speaker. Despite becoming the first   to win election to a seat in the U. S. Senate since Reconstruction, Edward Brooke came in for criticism for calling for “empathy” for the goals of protestors as he criticized tactics. Though Clinton in her senior thesis on Saul Alinsky lamented “Black Power demagogues” and “elitist arrogance and repressive intolerance” within the New Left, similar words coming out of a Republican necessitated a brief rebuttal. “Trust,” Rodham ironically observed in 1969, “this is one word that when I asked the class at our rehearsal what it was they wanted me to say for them, everyone came up to me and said ‘Talk about trust, talk about the lack of trust both for us and the way we feel about others. Talk about the trust bust.’ What can you say about it? What can you say about a feeling that permeates a generation and that perhaps is not even understood by those who are distrusted?” The “trust bust” certainly busted Clinton’s 2016 plans. She certainly did not even understand that people distrusted her. After Whitewater, Travelgate, the vast   conspiracy, Benghazi, and the missing emails, Clinton found herself the distrusted voice on Friday. There was a load of compromising on the road to the broadening of her political horizons. And distrust from the American people —  Trump edged her 48 percent to 38 percent on the question immediately prior to November’s election —  stood as a major reason for the closing of those horizons. Clinton described her vanquisher and his supporters as embracing a “lie,” a “con,” “alternative facts,” and “a   assault on truth and reason. ” She failed to explain why the American people chose his lies over her truth. “As the history majors among you here today know all too well, when people in power invent their own facts and attack those who question them, it can mark the beginning of the end of a free society,” she offered. “That is not hyperbole. ” Like so many people to emerge from the 1960s, Hillary Clinton embarked upon a long, strange trip. From high school Goldwater Girl and Wellesley College Republican president to Democratic politician, Clinton drank in the times and the place that gave her a degree. More significantly, she went from idealist to cynic, as a comparison of her two Wellesley commencement addresses show. Way back when, she lamented that “for too long our leaders have viewed politics as the art of the possible, and the challenge now is to practice politics as the art of making what appears to be impossible possible. ” Now, as the big woman on campus but the odd woman out of the White House, she wonders how her current station is even possible. “Why aren’t I 50 points ahead?” she asked in September. In May she asks why she isn’t president. The woman famously dubbed a “congenital liar” by Bill Safire concludes that lies did her in —  theirs, mind you, not hers. Getting stood up on Election Day, like finding yourself the jilted bride on your wedding day, inspires dangerous delusions.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = text[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "swedish-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = tokenizer.texts_to_sequences([input_text])\n",
    "input_tokens = pad_sequences(input_tokens, maxlen=MAX_LEN, \n",
    "                             padding='post', truncating='post')\n",
    "states_values = encoder_model.predict(input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "pretty-oriental",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seq = np.zeros(shape=(1, 1, NUM_WORDS + 1))\n",
    "target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "specific-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_seq[0, 0, target_word_index['[bos]']] = 1\n",
    "output_tokens, h, c =  decoder_model.predict([target_seq] + states_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "thirty-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens.shape\n",
    "sample_token_idx = np.argmax(output_tokens[0, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "alike-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = target_index_word[sample_token_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "competent-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seq = np.zeros((1, 1, NUM_WORDS + 1))\n",
    "target_seq[0, 0, sample_token_idx] = 1\n",
    "\n",
    "states_value = [h, c]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
