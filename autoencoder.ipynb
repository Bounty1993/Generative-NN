{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "hired-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Input, Conv2D, BatchNormalization, Dropout, Dense, Flatten, Reshape, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "handy-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Layer):\n",
    "    def __init__(self, num_conv_layers, conv_units, encoder_output_dim, input_dim=None,\n",
    "                 dropout_rate=None, name='encoder', **kwargs):\n",
    "        super(Encoder, self).__init__(name=name, **kwargs)\n",
    "        self.input_dim = input_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.input_layer = Input(shape=(self.input_dim))\n",
    "        self.conv_layers = []\n",
    "        for i in range(num_conv_layers):\n",
    "            conv_layer = Conv2D(filters = conv_units, \n",
    "                                kernel_size = (3, 3), \n",
    "                                strides = 2,\n",
    "                                padding = 'same',\n",
    "                                activation='relu',\n",
    "                                name = f'encode_conv_{i}')\n",
    "            self.conv_layers.append(conv_layer)\n",
    "        self.output_layer = Dense(encoder_output_dim)\n",
    "            \n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoder_layer = self.input_layer(inputs)\n",
    "        for conv_layer in self.conv_layers:\n",
    "            encoder_layer = conv_layer(encoder_layer)\n",
    "            encoder_layer = BatchNormalization(encoder_layer)\n",
    "            if dropout_rate is not None:\n",
    "                encoder_layer = Dropout(rate=dropout_rate)(encoder_layer)\n",
    "            \n",
    "        encoder_layer = Flatten(encoder_layer)\n",
    "        output_layer = self.output_layer(encoder_layer)\n",
    "        return output_layer\n",
    "    \n",
    "    \n",
    "def Decoder(Layers):\n",
    "    def __init__(self, num_conv_layers, conv_units, encoder_output_dim, \n",
    "                 dropout_rate=None, name='decoder', **kwargs):\n",
    "        self.decoder_input = Input(shape=(encoder_output_dim))\n",
    "        self.dense = Dense(np.prod())\n",
    "    \n",
    "    \n",
    "class Autoencoder(Model):\n",
    "    def __init__(self, num_conv_layers, conv_units, encoder_output_dim, input_dim=None,\n",
    "                 dropout_rate=None, **kwargs):\n",
    "        super(Autoencoder, self).__init__(**kwargs)\n",
    "        self.encoder = Encoder(num_conv_layers = num_conv_layers, \n",
    "                               conv_units = conv_units, \n",
    "                               encoder_output_dim = encoder_output_dim, \n",
    "                               input_dim = input_dim,\n",
    "                               dropout_rate = dropout_rate)\n",
    "        \n",
    "    def model(self):\n",
    "        input_layer = Input(Input(shape=(24, 24, 3)))\n",
    "        return Model(input_layer, self.call(input_layer))\n",
    "    \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.encoder(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "welsh-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder(num_conv_layers=3, conv_units=5, encoder_output_dim=10, input_dim=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "effective-angola",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_75\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_61 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_0 (Conv2D)      (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "encoder_conv_1 (Conv2D)      (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "encoder_conv_2 (Conv2D)      (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "encoder_conv_3 (Conv2D)      (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "encoder_output (Dense)       (None, 2)                 6274      \n",
      "=================================================================\n",
      "Total params: 117,698\n",
      "Trainable params: 117,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_conv_layers = 4\n",
    "conv_units = 64\n",
    "encoder_output_dim=2\n",
    "strides = [1,2,2,1]\n",
    "input_dim=(28, 28, 1)\n",
    "dropout_rate=0.2\n",
    "\n",
    "encoder_input = Input(shape=input_dim)\n",
    "x = encoder_input\n",
    "for i in range(num_conv_layers):\n",
    "    conv_layer = Conv2D(filters=conv_units,\n",
    "                        kernel_size=(3, 3),\n",
    "                        strides=strides[i],\n",
    "                        padding='same',\n",
    "                        activation='relu',\n",
    "                        name=f'encoder_conv_{i}')\n",
    "    x = conv_layer(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = Dropout(rate=dropout_rate)(x)\n",
    "\n",
    "shape_before_flat = K.int_shape(x)[1:]\n",
    "x = Flatten()(x)\n",
    "dense_layer = Dense(encoder_output_dim, name='encoder_output')\n",
    "encoder_output = dense_layer(x)\n",
    "\n",
    "encoder_model = Model(encoder_input, encoder_output)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "modified-baker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_81\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_63 (InputLayer)        [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 3136)              9408      \n",
      "_________________________________________________________________\n",
      "reshape_12 (Reshape)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_0 (Conv2DTransp (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "decoder_conv_1 (Conv2DTransp (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "decoder_conv_2 (Conv2DTransp (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "decoder_conv_final (Conv2DTr (None, 28, 28, 1)         577       \n",
      "=================================================================\n",
      "Total params: 120,769\n",
      "Trainable params: 120,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_input = Input(shape=encoder_output_dim)\n",
    "x = Dense(np.prod(shape_before_flat))(decoder_input)\n",
    "x = Reshape(shape_before_flat)(x)\n",
    "\n",
    "for i in range(num_conv_layers - 1):\n",
    "    conv_layer = Conv2DTranspose(filters=conv_units,\n",
    "                                 kernel_size=(3, 3),\n",
    "                                 strides=strides[i], \n",
    "                                 padding='same',\n",
    "                                 activation='relu',\n",
    "                                 name=f'decoder_conv_{i}')\n",
    "    x = conv_layer(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = Dropout(rate=dropout_rate)(x)\n",
    "\n",
    "output_layer = Conv2DTranspose(filters=1,\n",
    "                               kernel_size=(3, 3),\n",
    "                               strides=1, \n",
    "                               padding='same',\n",
    "                               activation='sigmoid',\n",
    "                               name=f'decoder_conv_final')\n",
    "x = output_layer(x)\n",
    "decoder_output = x\n",
    "\n",
    "decoder_model = Model(decoder_input, decoder_output)\n",
    "\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "incomplete-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = encoder_input\n",
    "model_output = decoder_model(encoder_output)\n",
    "\n",
    "model = Model(encoder_input, model_output)\n",
    "\n",
    "\n",
    "def r_loss(y_true, y_pred):\n",
    "    return K.mean(K.square(y_true - y_pred), axis = [1,2,3])\n",
    "\n",
    "model.compile(optimizer='adam', loss=r_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-stocks",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "greatest-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "established-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train = x_train.reshape(x_train.shape + (1,))\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_test = x_test.reshape(x_test.shape + (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "embedded-madison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.0895\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.0621\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 3s 84ms/step - loss: 0.0595\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.0580\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 3s 83ms/step - loss: 0.0569\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.0562\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 3s 84ms/step - loss: 0.0554\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.0546\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.0542\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.0535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17a88fb5d90>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train[:1000], x_train[:1000], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "arabic-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(x_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "guided-township",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17a88e92250>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(res[0], cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "reserved-riverside",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17a88ee1940>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0], cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-substitute",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
